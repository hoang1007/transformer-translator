{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.16.0-unknown is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/hoang/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/hoang/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "from model import Translator\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "src_tokenizer = AutoTokenizer.from_pretrained(config.SRC_MODEL_NAME)\n",
    "tgt_tokenizer = AutoTokenizer.from_pretrained(config.TGT_MODEL_NAME)\n",
    "\n",
    "translator = Translator.load_from_checkpoint(\n",
    "    \"../checkpoints/last.ckpt\",\n",
    "    src_tokenizer=src_tokenizer,\n",
    "    tgt_tokenizer=tgt_tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Khi nhỏ bé nhỏ.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.greedy_translate(\"When i was little\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.28848347067832947,\n",
       "  'Khi nhỏ, tôi nghĩ đất nước mình là tốt nhất thế giới.'),\n",
       " (0.34126970171928406,\n",
       "  'Khi nhỏ, tôi nghĩ rằng đất nước tôi là tốt nhất thế giới.'),\n",
       " (0.6581437587738037,\n",
       "  'Khi nhỏ, tôi nghĩ rằng đất nước mình là tốt nhất thế giới.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.beam_translate(\"When I was little, I thought my country was the best in the world.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "ckpt = torch.load(\"../checkpoints/last-v1.ckpt\", map_location=\"cpu\")\n",
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset mt_eng_vietnamese (/home/hoang/.cache/huggingface/datasets/mt_eng_vietnamese/iwslt2015-vi-en/1.0.0/53add551a01e9874588066f89d42925f9fad43db347199dad00f7e4b0c905a71)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "iwslt = load_dataset(\"mt_eng_vietnamese\", \"iwslt2015-vi-en\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'When I was little , I thought my country was the best on the planet , and I grew up singing a song called &quot; Nothing To Envy . &quot;',\n",
       " 'vi': 'Khi tôi còn nhỏ , Tôi nghĩ rằng BắcTriều Tiên là đất nước tốt nhất trên thế giới và tôi thường hát bài &quot; Chúng ta chẳng có gì phải ghen tị . &quot;'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iwslt[0][\"translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.2620276212692261,\n",
       "  'Chúng tôi dành rất nhiều thời gian nghiên cứu về lịch sử của Joel, nhưng chúng tôi chưa biết được nhiều về thế giới bên ngoài, ngoại trừ nước Mỹ, Nhật Bản là kẻ thù.'),\n",
       " (0.3884652853012085,\n",
       "  'Chúng tôi dành rất nhiều thời gian nghiên cứu về lịch sử của Jopest, nhưng chúng tôi chưa biết được nhiều về thế giới bên ngoài, ngoại trừ nước Mỹ, Nhật Bản là kẻ thù.'),\n",
       " (0.5975554585456848,\n",
       "  'Chúng tôi dành rất nhiều thời gian nghiên cứu về lịch sử của Joel, nhưng chúng tôi chưa từng học được nhiều về thế giới bên ngoài, ngoại trừ nước Mỹ, Nhật Bản là kẻ thù.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.beam_translate(iwslt[2][\"translation\"][\"en\"], beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ở trường , chúng tôi dành rất nhiều thời gian để học về cuộc đời của chủ tịch Kim II- Sung , nhưng lại không học nhiều về thế giới bên ngoài , ngoại trừ việc Hoa Kỳ , Hàn Quốc và Nhật Bản là kẻ thù của chúng tôi .'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iwslt[2][\"translation\"][\"vi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ở, chúng tôi đã dành rất nhiều thời gian nghiên cứu về lịch sử của Joel, ngoại trừ nước ngoài, ngoại trừ nước Mỹ, ngoại trừ nước Mỹ, Nhật Bản là kẻ thù địch.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.greedy_translate(iwslt[2][\"translation\"][\"en\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
